{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_pymongo import PyMongo, ObjectId\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "# app.config['MONGO_URI']='mongodb://omar1234:omar1234@cluster0-shard-00-00.ddf2s.mongodb.net:27017,cluster0-shard-00-01.ddf2s.mongodb.net:27017,cluster0-shard-00-02.ddf2s.mongodb.net:27017/SocialMedia?ssl=true&replicaSet=atlas-g1k44j-shard-0&authSource=admin&retryWrites=true&w=majority'\n",
    "# mongo=PyMongo(app)\n",
    "CORS(app)\n",
    "#db =mongo.db.users\n",
    "\n",
    "consumer_key=\"VAK69Ll6UrcDYWMs3neOQDkiA\"\n",
    "consumer_key_secret=\"ijMr1mzoIHUzXBs20UsEXaK90IL6fn1n9w47ocvhTRq2JF5jFn\"\n",
    "access_token=\"3075384460-34k2qIZVBjT6Xj3917Zfuc5SCrwysM1gV4k7pFM\"\n",
    "access_token_secret=\"aRLO6DUfT1MpSUGXGYJYfMKkxuYxfrbwlj7kzueGLDtQM\"\n",
    "auth=OAuthHandler(consumer_key,consumer_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api=tweepy.API(auth)\n",
    "\n",
    "client = MongoClient(\"mongodb://omar1234:omar1234@cluster0-shard-00-00.ddf2s.mongodb.net:27017,cluster0-shard-00-01.ddf2s.mongodb.net:27017,cluster0-shard-00-02.ddf2s.mongodb.net:27017/SocialMedia?ssl=true&replicaSet=atlas-g1k44j-shard-0&authSource=admin&retryWrites=true&w=majority\")\n",
    "db = client.get_database('SocialMedia')\n",
    "records = db.Test\n",
    "\n",
    "def callfunc(x):\n",
    "    x=5\n",
    "    print(\"VALUE IS \",x)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class confusion_matrix:\n",
    "  def __init__(self):\n",
    "    self.true_Real = 0\n",
    "    self.true_Fake = 0\n",
    "    self.false_Real = 0\n",
    "    self.false_Fake = 0\n",
    "    self.total = 0\n",
    "    self.right = 0\n",
    "  \n",
    "  def update_matrix(self , actual , predicted ):\n",
    "    self.total += 1\n",
    "    if actual == predicted:\n",
    "      self.right += 1\n",
    "      if actual == 'Positive':\n",
    "        self.true_Real += 1\n",
    "      else:\n",
    "        self.true_Fake += 1\n",
    "\n",
    "    if actual != predicted:\n",
    "      if actual == 'Positive':\n",
    "        self.false_Real += 1\n",
    "      else:\n",
    "        self.false_Fake += 1\n",
    "  \n",
    "  def results(self):\n",
    "    p = self.true_Real/(self.true_Real + self.false_Real )\n",
    "    r = self.true_Real/(self.true_Real + self.false_Fake )\n",
    "    print( \"Accuracy : \" , self.right/(self.total )  * 100)\n",
    "    print( \"Precision: \" , self.true_Real/(self.true_Real + self.false_Real ) * 100 )\n",
    "    print( \"Recall   : \" , self.true_Real/(self.true_Real + self.false_Fake )* 100 )\n",
    "    print( \"F1 score : \" , 2* ((p*r)/(p+r)) * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Negative' , 'Positive']\n",
    "\n",
    "Train = {}\n",
    "list_of_df = []\n",
    "\n",
    "path = r'C:/Users/omar/Desktop/TWITTER DATA' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "for filename in all_files:\n",
    "    data = pd.read_csv(filename, encoding='latin-1' , names = ['sentiment', 'id1' , 'Date' , 'query' , 'name', 'text'])\n",
    "    list_of_df.append(data)\n",
    "    \n",
    "data = pd.concat(list_of_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id1' , 'Date' , 'query' , 'name'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentiment\"].replace({0: \"Negative\", 4: \"Positive\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing Data into train and test Sets\n",
    "\n",
    "Split_Ratio = 0.8\n",
    "\n",
    "Train_df = data.iloc[: int(len(data)*Split_Ratio) , :].reset_index(drop=True)\n",
    "Test_df = data.iloc[int((len(data)*Split_Ratio)) + 1: , :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>is off into twon!  woop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@candydoodles hahaha...yeaah,me too.  i really...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@BIGWILLSMITH will y didn't u take me with you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Lying in bed listening to 1980s hits on my iPh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@Wolfgang114 I like the Rocky Horror Picture s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280007</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@atomictiki Listened yesterday. Hollywood-tone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280008</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@PeterOlson I'm dead broke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280009</th>\n",
       "      <td>Negative</td>\n",
       "      <td>packing .. tomorrow I'll leave  I'm happy/sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280010</th>\n",
       "      <td>Negative</td>\n",
       "      <td>SUNBURNT !! aaiyah, it hurts &amp;amp; im all red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280011</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just got to ballet. Haven't watched emily is i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text\n",
       "0        Positive                            is off into twon!  woop\n",
       "1        Negative  @candydoodles hahaha...yeaah,me too.  i really...\n",
       "2        Negative   @BIGWILLSMITH will y didn't u take me with you? \n",
       "3        Positive  Lying in bed listening to 1980s hits on my iPh...\n",
       "4        Negative  @Wolfgang114 I like the Rocky Horror Picture s...\n",
       "...           ...                                                ...\n",
       "1280007  Negative  @atomictiki Listened yesterday. Hollywood-tone...\n",
       "1280008  Negative                        @PeterOlson I'm dead broke \n",
       "1280009  Negative  packing .. tomorrow I'll leave  I'm happy/sad ...\n",
       "1280010  Negative  SUNBURNT !! aaiyah, it hurts &amp; im all red ...\n",
       "1280011  Positive  Just got to ballet. Haven't watched emily is i...\n",
       "\n",
       "[1280012 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = dict.fromkeys(classes,[])\n",
    "Test = dict.fromkeys(classes,[])\n",
    "\n",
    "for c in classes:\n",
    "  Train[c] = Train_df.loc[Train_df['sentiment'] == c ]['text'].tolist()\n",
    "  Test[c] = Test_df.loc[Test_df['sentiment'] == c]['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVocabulary(T , stopwords = False):\n",
    "  V = set()\n",
    "  for c in T:\n",
    "    for text in T[c]:\n",
    "      words = text.split()\n",
    "      for word in words:\n",
    "        if stopwords == True and word in stop_words:\n",
    "          continue\n",
    "        V.add(word)\n",
    "  V = list(V)\n",
    "  return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainMultinomialNB(C, T , booleanNB = False , stopwords = False ):\n",
    "  V = makeVocabulary(T , stopwords)\n",
    "  Priors = {}\n",
    "  condProb = {}\n",
    "\n",
    "  sum_of_priors = 0\n",
    "\n",
    "  for c in C:\n",
    "    sum_of_priors += len(T[c])\n",
    "  \n",
    "  for c in C:\n",
    "    Priors[c] = len(T[c])/sum_of_priors\n",
    "\n",
    "    doc = []\n",
    "    for text in T[c]:\n",
    "      templist = text.split()\n",
    "\n",
    "      if booleanNB == True:\n",
    "        doc += list(set(text.split()))\n",
    "      else:\n",
    "        doc += text.split()\n",
    "\n",
    "    count_words = dict.fromkeys( V , 0 )\n",
    "    for word in doc:\n",
    "      if word in count_words.keys():\n",
    "        if stopwords == True and word in stop_words:\n",
    "          continue\n",
    "        count_words[word] += 1\n",
    "\n",
    "    \n",
    "    for word in V:\n",
    "      condProb[word , c] = ( count_words[word] + 1 ) / ( len(doc) + len(V) ) \n",
    "\n",
    "  return V , Priors , condProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyMultinomialNB(C, V, prior, condprob, t , stopwords = False):\n",
    "  words_from_text = t.split()\n",
    "  score = dict.fromkeys(C , 0)\n",
    "  \n",
    "  for c in C:\n",
    "    score[c] = math.log(prior[c])\n",
    "    for word in words_from_text:\n",
    "      if stopwords == True and word in stop_words:\n",
    "        continue\n",
    "      if (word , c) in condprob.keys():\n",
    "        score[c] += math.log(condprob[word , c])\n",
    "\n",
    "  if (score['Positive'] > score['Negative']):\n",
    "    return 'Positive'\n",
    "  else:\n",
    "    return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab , priors , cond_Prob = TrainMultinomialNB(classes , Train , booleanNB = False , stopwords = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  78.14544909094319\n",
      "Precision:  72.82349844580366\n",
      "Recall   :  81.39003873281364\n",
      "F1 score :  76.86883353564353\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_of_NB_withStopWords = confusion_matrix()\n",
    "for c in classes:\n",
    "  for text in Test[c]:\n",
    "    result = ApplyMultinomialNB(classes, vocab, priors, cond_Prob, text , stopwords = False)\n",
    "    results_of_NB_withStopWords.update_matrix(c , result)\n",
    "  \n",
    "results_of_NB_withStopWords.results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentimental Anlaysis Model end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOTS IDENTIFICATION START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= 'BotsData.csv'\n",
    "TrainingData = pd.read_csv (r'C:/Users/omar/Desktop/BOT DATA/'+file)\n",
    "bot = TrainingData[TrainingData.bot==1]\n",
    "nonbot = TrainingData[TrainingData.bot==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\3634027558.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bot['friendsfollowersRatio'] = bot.friends_count/bot.followers_count\n",
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\3634027558.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonbot['friendsfollowersRatio'] = nonbot.friends_count/nonbot.followers_count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(952, 21)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot['friendsfollowersRatio'] = bot.friends_count/bot.followers_count\n",
    "bot[bot.friendsfollowersRatio<1].shape\n",
    "\n",
    "nonbot['friendsfollowersRatio'] = nonbot.friends_count/nonbot.followers_count\n",
    "nonbot[nonbot.friendsfollowersRatio<1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "botslistedcountdf = bot[bot.listed_count<16000]\n",
    "nonbotslistedcountdf = nonbot[nonbot.listed_count<16000]\n",
    "\n",
    "botsverifieddf = botslistedcountdf[botslistedcountdf.verified==False]\n",
    "botsscreennamehasbotdf = botsverifieddf[(botsverifieddf.screen_name.str.contains(\"bot\", case=False)==True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\3136925940.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bot['screennamebinary'] = (bot.screen_name.str.contains(\"bot\", case=False)==True)\n",
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\3136925940.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bot['locationbinary'] = (bot.location.isnull())\n",
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\3136925940.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bot['verifiedbinary'] = (bot.verified==False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1321, 24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (bot.screen_name.str.contains(\"bot\", case=False)==True)|(bot.description.str.contains(\"bot\", case=False)==True)|(bot.location.isnull())|(bot.verified==False)\n",
    "\n",
    "bot['screennamebinary'] = (bot.screen_name.str.contains(\"bot\", case=False)==True)\n",
    "bot['locationbinary'] = (bot.location.isnull())\n",
    "bot['verifiedbinary'] = (bot.verified==False)\n",
    "bot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\2645627122.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonbot['screennamebinary'] = (nonbot.screen_name.str.contains(\"bot\", case=False)==False)\n",
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\2645627122.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonbot['locationbinary'] = (nonbot.location.isnull()==False)\n",
      "C:\\Users\\omar\\AppData\\Local\\Temp\\ipykernel_24968\\2645627122.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonbot['verifiedbinary'] = (nonbot.verified==True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1476, 24)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (nonbot.screen_name.str.contains(\"bot\", case=False)==False)| (nonbot.description.str.contains(\"bot\", case=False)==False) |(nonbot.location.isnull()==False)|(nonbot.verified==True)\n",
    "\n",
    "nonbot['screennamebinary'] = (nonbot.screen_name.str.contains(\"bot\", case=False)==False)\n",
    "nonbot['locationbinary'] = (nonbot.location.isnull()==False)\n",
    "nonbot['verifiedbinary'] = (nonbot.verified==True)\n",
    "\n",
    "nonbot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2797, 24)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([bot, nonbot])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open('C:/Users/omar/Desktop/BOT DATA/BotsData.csv', mode='r', encoding='utf-8', errors='ignore')\n",
    "\n",
    "TrainingData = pd.read_csv(file)\n",
    "\n",
    "StopWords = r'bot|b0t|cannabis|tweet me|mishear|follow me|updates every|gorilla|yes_ofc|forget' \\\n",
    "                    r'expos|kill|bbb|truthe|fake|anony|free|virus|funky|RNA|kuck|jargon' \\\n",
    "                    r'nerd|swag|jack|bang|bonsai|chick|prison|paper|pokem|freak|ffd|dunia|clone|genie|bbb' \\\n",
    "                    r'ffd|onlyman|emoji|joke|troll|droop|free|every|wow|cheese|yeah|bio|magic|wizard|face'\n",
    "\n",
    "###STOP WORDS TAKEN FROM https://github.com/martha92/MeTooAnalysis/blob/e2dd051866a79ccb065507d304dfd98168e6b0c2/bot_human/bot_human_custom.py\n",
    "            \n",
    "TrainingData['screennamebinary'] = TrainingData.screen_name.str.contains(StopWords, case=False, na=False)\n",
    "TrainingData['namebinary'] = TrainingData.name.str.contains(StopWords, case=False, na=False)\n",
    "TrainingData['descriptionbinary'] = TrainingData.description.str.contains(StopWords, case=False, na=False)\n",
    "TrainingData['statusbinary'] = TrainingData.status.str.contains(StopWords, case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData['listedcountbinary'] = (TrainingData.listed_count>20000)==False\n",
    "feature = ['screennamebinary', 'namebinary', 'descriptionbinary', 'statusbinary', 'verified', 'followers_count', 'friends_count', 'statuses_count', 'listedcountbinary', 'bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Accuracy: 0.88412\n",
      "Test Accuracy: 0.87429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = TrainingData[feature].iloc[:,:-1]\n",
    "y = TrainingData[feature].iloc[:,-1]\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=50, min_samples_split=10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "\n",
    "dt = dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Trainig Accuracy: %.5f\" %accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy: %.5f\" %accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      screennamebinary  namebinary  descriptionbinary  statusbinary  verified  \\\n",
      "2409             False       False              False         False     False   \n",
      "416              False       False               True         False     False   \n",
      "1193             False       False              False         False     False   \n",
      "1970             False       False               True         False     False   \n",
      "1854             False       False              False          True      True   \n",
      "...                ...         ...                ...           ...       ...   \n",
      "931               True       False               True          True     False   \n",
      "1626             False       False              False         False      True   \n",
      "925              False       False               True          True     False   \n",
      "2440             False       False              False         False      True   \n",
      "1394             False       False              False          True      True   \n",
      "\n",
      "      followers_count  friends_count  statuses_count  listedcountbinary  \n",
      "2409               32             54              16               True  \n",
      "416           1474799              1           20990               True  \n",
      "1193                2            492              79               True  \n",
      "1970             5273            293            6636               True  \n",
      "1854             5766            333             358               True  \n",
      "...               ...            ...             ...                ...  \n",
      "931                70              0           16312               True  \n",
      "1626          1039625            176             825               True  \n",
      "925              9212              2            8996               True  \n",
      "2440          3062495           9465            6851               True  \n",
      "1394          1474073             40            8601               True  \n",
      "\n",
      "[700 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Checkbot(param):\n",
    "    \n",
    "    user=api.get_user(screen_name=param )\n",
    "    population_dict = {'screennamebinary': [user.screen_name],\n",
    "                   'namebinary': [user.name],\n",
    "                   'descriptionbinary': [user.description],\n",
    "                   'statusbinary': [user.status],\n",
    "                   'verified': [user.verified],\n",
    "                   'followers_count': [user.followers_count],\n",
    "                   'friends_count': [user.friends_count],\n",
    "                   'statuses_count': [user.statuses_count],\n",
    "                   'listedcountbinary': [user.listed_count]}\n",
    "                \n",
    "    population = pd.DataFrame(population_dict)\n",
    "\n",
    "    population['screennamebinary'] = population.screennamebinary.str.contains(StopWords, case=False, na=False)|(population.screennamebinary.str.contains(\"bot\", case=False)==True)\n",
    "    population['namebinary'] = population.namebinary.str.contains(StopWords, case=False, na=False)\n",
    "    population['descriptionbinary'] = population.descriptionbinary.str.contains(StopWords, case=False, na=False)|(population.descriptionbinary.str.contains(\"bot\", case=False)==True)\n",
    "    population['statusbinary'] = population.statusbinary.str.contains(StopWords, case=False, na=False)\n",
    "    population['listedcountbinary'] = (population.listedcountbinary>20000)==False\n",
    "\n",
    "    if(dt.predict(population)==0):\n",
    "        return \"Non Bot\"\n",
    "    else:\n",
    "        return \"Bot\"\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOTS IDENTIFICATION END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return '<h1> WELCOME TO FLASK API </h1>'\n",
    "\n",
    "@app.route('/testing', methods=['GET'])\n",
    "def check():\n",
    "    id=1\n",
    "    x=10\n",
    "    callfunc(x)\n",
    "    args = request.args\n",
    "    name = str(args.get('myparam'))\n",
    "    search_words = name\n",
    "    date_since = \"2018-11-16\"\n",
    "    #tweets = tweepy.Cursor(api.search_tweets,\n",
    "     #           q=search_words,\n",
    "      #          lang=\"en\" ,tweet_mode='extended').items(10)\n",
    "\n",
    "    # Iterate and print tweets\n",
    "    #dict={\"tweet\":\"\"}\n",
    "    tweet_list=[]\n",
    "\n",
    "    #for tweet in tweets:\n",
    "       # tweet_list.append({\"tweet\":tweet.full_text})\n",
    "    for tweet_info in tweepy.Cursor(api.search_tweets, q=search_words, lang = \"en\", tweet_mode=\"extended\").items(10):\n",
    "        if \"retweeted_status\" in dir(tweet_info):\n",
    "            tweet=tweet_info.retweeted_status.full_text\n",
    "            sentiment=ApplyMultinomialNB(classes, vocab, priors, cond_Prob, tweet_info.retweeted_status.full_text , stopwords = False)\n",
    "            loc=tweet_info.user.location\n",
    "            user_name=tweet_info.user.screen_name\n",
    "            tweet_list.append({\"ID\":id,\"Tweet\":tweet,\"Sentiment\":sentiment,\"Location\":loc,\"User Name\":user_name})\n",
    "            id=id+1            \n",
    "    #print(tweet)\n",
    "        else:\n",
    "            tweet=tweet_info.full_text\n",
    "            sentiment=ApplyMultinomialNB(classes, vocab, priors, cond_Prob, tweet_info.full_text , stopwords = False)\n",
    "            loc=tweet_info.user.location\n",
    "            user_name=tweet_info.user.screen_name\n",
    "            tweet_list.append({\"ID\":id,\"Tweet\":tweet,\"Sentiment\":sentiment,\"Location\":loc,\"User Name\":user_name})\n",
    "            id=id+1\n",
    "    #print(tweet_list)\n",
    "    return jsonify(tweet_list)\n",
    "    #return '<h1> TESTING </h1>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/countertrend', methods=['GET'])\n",
    "def counter():\n",
    "    id=1\n",
    "    x=10\n",
    "    callfunc(x)\n",
    "    args = request.args\n",
    "    name = str(args.get('myparam'))\n",
    "    search_words = name\n",
    "    date_since = \"2018-11-16\"\n",
    "    #tweets = tweepy.Cursor(api.search_tweets,\n",
    "     #           q=search_words,\n",
    "      #          lang=\"en\" ,tweet_mode='extended').items(10)\n",
    "\n",
    "    # Iterate and print tweets\n",
    "    #dict={\"tweet\":\"\"}\n",
    "    tweet_list=[]\n",
    "    Positive_tweets=[]\n",
    "    #for tweet in tweets:\n",
    "       # tweet_list.append({\"tweet\":tweet.full_text})\n",
    "    for tweet_info in tweepy.Cursor(api.search_tweets, q=search_words, lang = \"en\", tweet_mode=\"extended\").items(10):\n",
    "        if \"retweeted_status\" in dir(tweet_info):\n",
    "            tweet=tweet_info.retweeted_status.full_text\n",
    "            sentiment=ApplyMultinomialNB(classes, vocab, priors, cond_Prob, tweet_info.retweeted_status.full_text , stopwords = False)\n",
    "            loc=tweet_info.user.location\n",
    "            user_name=tweet_info.user.screen_name\n",
    "            tweet_list.append({\"Tweet\":tweet,\"Sentiment\":sentiment,\"Location\":loc,\"User Name\":user_name})\n",
    "    #print(tweet)\n",
    "        else:\n",
    "            tweet=tweet_info.full_text\n",
    "            sentiment=ApplyMultinomialNB(classes, vocab, priors, cond_Prob, tweet_info.full_text , stopwords = False)\n",
    "            loc=tweet_info.user.location\n",
    "            user_name=tweet_info.user.screen_name\n",
    "            tweet_list.append({\"Tweet\":tweet,\"Sentiment\":sentiment,\"Location\":loc,\"User Name\":user_name})\n",
    "    #print(tweet_list)\n",
    "    for i in range(0,len(tweet_list)):\n",
    "      if(tweet_list[i][\"Sentiment\"]==\"Positive\"):\n",
    "         Positive_tweets.append({\"ID\":id,\"Tweet\":tweet_list[i][\"Tweet\"]})\n",
    "         id=id+1\n",
    "    return jsonify(Positive_tweets)\n",
    "    #return '<h1> TESTING </h1>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/bots', methods=['GET'])\n",
    "def check_bots():\n",
    "    id=1\n",
    "    args = request.args\n",
    "    name = str(args.get('myparam'))\n",
    "    search_words = name\n",
    "    date_since = \"2018-11-16\"\n",
    "    #tweets = tweepy.Cursor(api.search_tweets,\n",
    "     #           q=search_words,\n",
    "      #          lang=\"en\" ,tweet_mode='extended').items(10)\n",
    "\n",
    "    # Iterate and print tweets\n",
    "    #dict={\"tweet\":\"\"}\n",
    "    tweet_list=[]\n",
    "\n",
    "    #for tweet in tweets:\n",
    "       # tweet_list.append({\"tweet\":tweet.full_text})\n",
    "    for tweet_info in tweepy.Cursor(api.search_tweets, q=search_words, lang = \"en\", tweet_mode=\"extended\").items(10):\n",
    "        if \"retweeted_status\" in dir(tweet_info):\n",
    "            tweet=tweet_info.retweeted_status.full_text\n",
    "            sentiment=ApplyMultinomialNB(classes, vocab, priors, cond_Prob, tweet_info.retweeted_status.full_text , stopwords = False)\n",
    "            loc=tweet_info.user.location\n",
    "            user_name=tweet_info.user.screen_name\n",
    "            status=Checkbot(tweet_info.user.screen_name)\n",
    "            tweet_list.append({\"ID\":id,\"Tweet\":tweet,\"Sentiment\":sentiment,\"Location\":loc,\"User Name\":user_name,\"Account Status\":status})\n",
    "            id=id+1\n",
    "            \n",
    "    #print(tweet)\n",
    "        else:\n",
    "            tweet=tweet_info.full_text\n",
    "            sentiment=ApplyMultinomialNB(classes, vocab, priors, cond_Prob, tweet_info.full_text , stopwords = False)\n",
    "            loc=tweet_info.user.location\n",
    "            user_name=tweet_info.user.screen_name\n",
    "            status=Checkbot(tweet_info.user.screen_name)\n",
    "            tweet_list.append({\"ID\":id,\"Tweet\":tweet,\"Sentiment\":sentiment,\"Location\":loc,\"User Name\":user_name,\"Account Status\":status})\n",
    "            id=id+1\n",
    "\n",
    "    #print(tweet_list)\n",
    "    return jsonify(tweet_list)\n",
    "    #return '<h1> TESTING </h1>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/users', methods=['GET'])\n",
    "def create_user():\n",
    "    id = records.insert({'content': [{\"tweet\": \"Lets go Pakistan\", \"likes\": 5}, {\n",
    "                        \"tweet\": \"Pakistan Zindabad\", \"likes\": 5}], \"Trend\": \"#Pakistan\"})\n",
    "    return jsonify({'id': str(ObjectId(id)), 'msg': \"User added successfully\"})\n",
    "\n",
    "\n",
    "@app.route('/trends', methods=['GET'])\n",
    "def get_trends():\n",
    "    trends = []\n",
    "    for tren in records.find():\n",
    "        trends.append({\n",
    "            '_id': str(ObjectId(tren['_id'])),\n",
    "            'content': tren['content'],\n",
    "            'Trend': tren['Trend']\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route('/trends/<id>', methods=['GET'])\n",
    "def get_trend(id):\n",
    "    trend = records.find_one({'_id':ObjectId(id)})\n",
    "    return jsonify({\n",
    "        '_id': str(ObjectId(trend['_id'])),\n",
    "        'content': trend['content'],\n",
    "        'Trend': trend['Trend']\n",
    "    })   \n",
    "@app.route('/trends/CivilWar', methods=['GET'])\n",
    "def get_trendCivilWar():\n",
    "    trend = records.find_one({'_id':ObjectId('617aa63aa2071ec120abdfd0')})\n",
    "    return jsonify({\n",
    "        '_id': str(ObjectId(trend['_id'])),\n",
    "        'content': trend['content'],\n",
    "        'Trend': trend['Trend']\n",
    "    })   \n",
    "@app.route('/trends/StopBalochGenocide', methods=['GET'])\n",
    "def get_trendStopBalochGenocide():\n",
    "    trend = records.find_one({'_id':ObjectId('61c3678bd4b2d3de32ad8a63')})\n",
    "    return jsonify({\n",
    "        '_id': str(ObjectId(trend['_id'])),\n",
    "        'content': trend['content'],\n",
    "        'Trend': trend['Trend']\n",
    "    }) \n",
    "@app.route('/trends/SanctionPakistan', methods=['GET'])\n",
    "def get_trendSanctionPakistan():\n",
    "    trend = records.find_one({'_id':ObjectId('61c39927e345142a93816962')})\n",
    "    return jsonify({\n",
    "        '_id': str(ObjectId(trend['_id'])),\n",
    "        'content': trend['content'],\n",
    "        'Trend': trend['Trend']\n",
    "    })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Apr/2022 18:26:36] \"\u001b[37mGET /trends/StopBalochGenocide HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE IS  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Apr/2022 18:27:34] \"\u001b[37mGET /testing?myparam=LahoreJalsa HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [22/Apr/2022 18:28:52] \"\u001b[37mGET /bots?myparam=امپوڑٹڈ_حکومت_نامنظور HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [22/Apr/2022 18:29:48] \"\u001b[37mGET /bots?myparam=Imran%20Khan HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE IS  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Apr/2022 18:31:09] \"\u001b[37mGET /countertrend?myparam=امپوڑٹڈ_حکومت_نامنظور HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
